{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Importing Libraries**"},{"metadata":{},"cell_type":"markdown","source":"importing traing data and test data and drop Id"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV ,RepeatedKFold\nfrom sklearn.model_selection import train_test_split,cross_val_score, KFold \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport sklearn.metrics as sklm\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndata_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ntrain= data_train.copy()\ntest = data_test.copy()\ntrain = train.drop('Id', axis=1)\ntest = test.drop('Id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring and cleanig the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the \"info\"  function shows that there is a lot of missing data so as we calculate the percentage of the NaN value we found that **Alley** **PoolQC** **Fence** **MiscFeature** have more than 80% of data is NaN so the feature is not reliable we gonna exclude them"},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns int tain set have more than 80% of nan \nnan_values_train = train.isnull().sum()\npourcentage_train =pd.DataFrame((np.array(nan_values_train)/1459)*100 ,index=nan_values_train.index)\npourcentage_train[pourcentage_train[0]>80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns int test set have more than 80% of nan values\n\nnan_values_test = test.isnull().sum()\npourcentage_test = pd.DataFrame((np.array(nan_values_train)/1459)*100 ,index=nan_values_train.index)\npourcentage_test[pourcentage_test[0]>80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)\n\ntest = test.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for other columns, we will change by the most **frequent** if the type of data **object** and with the **mean** if the type of data does **not object (int float...)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filling the nan for tain set\nmissing_value_train = train.isnull().sum()\n\nfor col in list(missing_value_train.index):\n    if train[col].dtype == 'object':\n        train[col].fillna(train[col].value_counts().index[0], inplace=True)\n    else:\n        train[col].fillna(train[col].mean(), inplace=True)\n        \n# filling the nan for test set        \nmissing_value_test = test.isnull().sum()\n\nfor col in list(missing_value_test.index):\n    if test[col].dtype == 'object':\n        test[col].fillna(test[col].value_counts().index[0], inplace=True)\n    else:\n        test[col].fillna(test[col].mean(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical train data\n\ntrain=train.apply(LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.apply(LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train: \\n{}\".format(train.dtypes.value_counts()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the train data to feautures X and target y\ny = np.ravel(np.array(train[['SalePrice']]))            \nX = train.drop(['SalePrice'], axis=1)\n             \nprint(y.shape)\nprint(X.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #Splitting the dataset into the Training set and Test set\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#createing Root Mean Squared Logarithmic Error (RMSLE) function\n\ndef rmsle (y_test, y_pred):\n    return round(np.sqrt(sklm.mean_squared_error(y_test, y_pred)),10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set the KFold function\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**> Finging the alpha parameter fo Ridge **"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# define model\nmodel = Ridge()\n# define model evaluation method\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['alpha'] = np.arange(0, 1, 0.01)\n# define search\nsearch = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(X_train, y_train)\n# summarize\nprint('MAE: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## set Ridge Regulariztion (L2)\n## Find Alpha\n\nridge = Ridge()\nparam = {'alpha': [a for a in range(50, 70)]}\n\nridge_reg = GridSearchCV(ridge, param_grid=param, scoring='neg_mean_squared_error'\n                     , cv=10)\n\nridge_reg.fit(X_train, y_train)\nprint(f\"The best value in Alpha: {ridge_reg.best_params_}\")\nprint(f\"The best score: {math.sqrt(-ridge_reg.best_score_)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_mod = Ridge(alpha=58)\nridge_mod.fit(X_train, y_train)\nridge_mod_train = ridge_mod.predict(X_train)\nridge_mod_test = ridge_mod.predict(X_test)\n\nprint(f'Root Mean Square Error train =  {rmsle(y_train, ridge_mod_train)}')\nprint(f'Root Mean Square Error test =  {rmsle(y_test, ridge_mod_test)}')   \n\nMSEs = cross_val_score(ridge_mod, X, y, \n                       scoring='neg_mean_squared_error', \n                       cv=kfolds)\n\nfor i,j in enumerate(MSEs):\n    j= math.sqrt(np.mean(-j))\n    print(f'Fold {i}: {round(j,4)}')\n    \nprint(f'Mean RMSE in Ridge: {round(math.sqrt(np.mean(-MSEs)),10)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlasso = Lasso()\nparams = {'alpha': [0.1, 1, 10]}\n\nlasso_reg = GridSearchCV(lasso, param_grid=param, cv=kfolds, scoring='neg_mean_squared_error')\n\nlasso_reg.fit(X_train, y_train)\nprint(f'The best value of lasso: {lasso_reg.best_params_}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlasso_mod = Lasso(alpha=50)\nlasso_mod.fit(X_train, y_train)\nlasso_mod_train = lasso_mod.predict(X_train)\nlasso_mod_test = lasso_mod.predict(X_test)\n\nprint(f'Root Mean Square Error train =  {str(rmsle(y_train, lasso_mod_train))}')\nprint(f'Root Mean Square Error test =  {rmsle(y_test, lasso_mod_test)}')\n\nLasso_CV = Lasso(alpha=1)\nMSEs = cross_val_score(lasso_mod, X, y, scoring='neg_mean_squared_error', cv=kfolds)\n\nfor i,j in enumerate(MSEs):\n    j= math.sqrt(np.mean(-j))\n    print(f'Fold {i}: {round(j,4)}')\n\nprint(f'Mean Lasso: {round(math.sqrt(np.mean(-MSEs)),10)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set RandomForest model\nfrom sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor(n_estimators=1400,\n                                      max_depth=13,\n                                      min_samples_split=5,\n                                      min_samples_leaf=5,\n                                      max_features=None,\n                                      random_state=42,\n                                      oob_score=True\n                                     )\n\nrandom_for = random_forest.fit(X_train, y_train)\nrandom_for_mod = random_for.predict(X_test)\n\nprint(f'Root Mean Square Error test = {rmsle(y_test, random_for_mod)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\n## Voting in esemble\n\nvote_mod = VotingRegressor([('Ridge', ridge_mod), ('Lasso', lasso_mod), \n                             ('Random_forest', random_forest)])\nvote= vote_mod.fit(X_train, y_train.ravel())\nvote_pred=vote.predict(X_test)\n\nprint(f'Root Mean Square Error test = {rmsle(y_test, vote_pred)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set XGBRegressor model\nfrom xgboost import XGBRegressor\nxgb_regress = XGBRegressor(learning_rate=0.01,\n                         n_estimators=3600,\n                         max_depth=4, min_child_weight=1,\n                         gamma=0.6, scale_pos_weight=1, \n                         seed=27, reg_alpha=0.00006 )\n\nxg_mod = xgb_regress.fit(X_train, y_train)\nxg_pred = xg_mod.predict(X_test)\n\nprint(f'Root Mean Square Error test =  {rmsle(y_test, xg_pred)}') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.regressor import StackingCVRegressor\nmodel = [ridge_mod, lasso_mod, vote_mod]\n\n## Stacking in ensemble\n\nstack = StackingCVRegressor(regressors=model, \n                           meta_regressor=xgb_regress, \n                            use_features_in_secondary=True)\n\nstack_mod=stack.fit(X_train, y_train.ravel())\nstacking_pred=stack_mod.predict(X_test)\n\nprint(f'Root Mean Square Error test = {rmsle(y_test, stacking_pred)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in lr_list :\n    gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, y_train)\n    stackin_pred = gb_clf.predict(X_train)\n    print(\"Learning rate: \", learning_rate)\n    print(f'Root Mean Square Error test = {rmsle(y_test, stacking_pred)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_mod_test_data_pred=ridge_mod.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission = pd.DataFrame({\n    \"Id\": data_test[\"Id\"],\n    \"SalePrice\": lasso_mod_test_data_pred\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission_test_set.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comapre between pridcted result and data result\nsale_price_compare = pd.DataFrame({\n    \"train sale price desc\": train.describe().iloc[:, -1],\n    \"test sale price desc\": submission.describe().iloc[:, -1]\n    },index=['count','mean','std','min','25%','50%','75%','max' ])\nsale_price_compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}